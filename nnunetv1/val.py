# validate_with_existing_weights.py
import torch
import os
import numpy as np
from collections import OrderedDict
from nnunet.training.network_training.nnUNetTrainerV2 import nnUNetTrainerV2
from nnunet.network_architecture.generic_UNet import Generic_UNet
from nnunet.network_architecture.initialization import InitWeights_He
from nnunet.utilities.nd_softmax import softmax_helper
from batchgenerators.utilities.file_and_folder_operations import *
from torch import nn

class WeightValidator(nnUNetTrainerV2):
    """
    ç²¾ç®€çš„æƒé‡éªŒè¯å™¨ï¼ŒåªåŒ…å«éªŒè¯åŠŸèƒ½ï¼Œä¸åŒ…å«è®­ç»ƒ
    """
    
    def __init__(self, plans_file, fold, output_folder=None, dataset_directory=None):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼Œä½†è·³è¿‡è®­ç»ƒç›¸å…³çš„è®¾ç½®
        super().__init__(plans_file, fold, output_folder, dataset_directory)
        
        # ç¦ç”¨è®­ç»ƒç›¸å…³åŠŸèƒ½
        self.training = False
        
    def initialize_for_validation(self):
        """åªåˆå§‹åŒ–éªŒè¯æ‰€éœ€çš„éƒ¨åˆ†"""
        if not self.was_initialized:
            maybe_mkdir_p(self.output_folder)
            
            # åŠ è½½plansæ–‡ä»¶
            self.load_plans_file()
            self.process_plans(self.plans)
            
            # è®¾ç½®æ•°æ®å¢å¼ºå‚æ•°ï¼ˆç”¨äºéªŒè¯æ—¶çš„é¢„å¤„ç†ï¼‰
            self.setup_DA_params()
            
            # åˆå§‹åŒ–ç½‘ç»œ
            self.initialize_network()
            
            # è·å–æ•°æ®åŠ è½½å™¨
            self.folder_with_preprocessed_data = join(self.dataset_directory, self.plans['data_identifier'] + "_stage%d" % self.stage)
            self.dl_tr, self.dl_val = self.get_basic_generators()
            
            self.was_initialized = True
            self.print_to_log_file("Validator initialized successfully")
    
    def load_weights(self, weights_path):
        """åŠ è½½æƒé‡æ–‡ä»¶"""
        if not isfile(weights_path):
            raise FileNotFoundError(f"Weights file not found: {weights_path}")
        
        self.print_to_log_file(f"Loading weights from: {weights_path}")
        checkpoint = torch.load(weights_path, map_location='cpu', weights_only=False)
        
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
            # å¤„ç†å¯èƒ½çš„DataParallelåŒ…è£…
            new_state_dict = OrderedDict()
            for k, v in state_dict.items():
                if k.startswith('module.'):
                    name = k[7:]  # remove 'module.' prefix
                else:
                    name = k
                new_state_dict[name] = v
            
            # åŠ è½½æƒé‡
            self.network.load_state_dict(new_state_dict)
            self.print_to_log_file("âœ… Weights loaded successfully")
            
            # æ‰“å°æƒé‡ä¿¡æ¯
            if 'epochs_used' in checkpoint:
                self.print_to_log_file(f"Epochs used for averaging: {checkpoint['epochs_used']}")
            if 'val_losses' in checkpoint:
                best_loss = min(checkpoint['val_losses'])
                self.print_to_log_file(f"Best validation loss: {best_loss:.4f}")
        else:
            # å¦‚æœæ²¡æœ‰state_dictï¼Œå‡è®¾æ–‡ä»¶ç›´æ¥åŒ…å«æƒé‡
            self.network.load_state_dict(checkpoint)
            self.print_to_log_file("âœ… Weights loaded successfully (direct state_dict)")
    
    def validate_with_loaded_weights(self, validation_folder_name='validation_loaded_weights'):
        """ä½¿ç”¨åŠ è½½çš„æƒé‡è¿›è¡ŒéªŒè¯"""
        self.print_to_log_file(f"Starting validation with folder name: {validation_folder_name}")
        
        # è®¾ç½®ç½‘ç»œä¸ºè¯„ä¼°æ¨¡å¼
        self.network.eval()
        
        # è¿è¡ŒéªŒè¯
        results = self.validate(
            do_mirroring=True,
            use_sliding_window=True,
            step_size=0.5,
            save_softmax=True,
            use_gaussian=True,
            overwrite=True,
            validation_folder_name=validation_folder_name,
            debug=False,
            all_in_gpu=False
        )
        
        return results

def validate_single_weights(weights_path, plans_file, fold=0, output_folder=None, dataset_directory=None):
    """
    éªŒè¯å•ä¸ªæƒé‡æ–‡ä»¶
    
    Args:
        weights_path: æƒé‡æ–‡ä»¶è·¯å¾„
        plans_file: plansæ–‡ä»¶è·¯å¾„
        fold: äº¤å‰éªŒè¯çš„fold
        output_folder: è¾“å‡ºæ–‡ä»¶å¤¹
        dataset_directory: æ•°æ®é›†ç›®å½•
    """
    
    print(f"ğŸ” Validating weights: {weights_path}")
    
    # å¦‚æœæœªæŒ‡å®šè¾“å‡ºæ–‡ä»¶å¤¹ï¼Œä½¿ç”¨æƒé‡æ–‡ä»¶æ‰€åœ¨ç›®å½•
    if output_folder is None:
        output_folder = os.path.dirname(weights_path)
    
    # åˆ›å»ºéªŒè¯å™¨å®ä¾‹
    validator = WeightValidator(
        plans_file=plans_file,
        fold=fold,
        output_folder=output_folder,
        dataset_directory=dataset_directory
    )
    
    try:
        # åˆå§‹åŒ–éªŒè¯å™¨
        validator.initialize_for_validation()
        
        # åŠ è½½æƒé‡
        validator.load_weights(weights_path)
        
        # è¿è¡ŒéªŒè¯
        validation_folder_name = f"validation_{os.path.basename(weights_path).replace('.pth', '')}"
        results = validator.validate_with_loaded_weights(validation_folder_name)
        
        print(f"âœ… Validation completed! Results saved in: {join(output_folder, validation_folder_name)}")
        return results
        
    except Exception as e:
        print(f"âŒ Validation failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def validate_multiple_weights(weights_dir, plans_file, fold=0, output_folder=None, dataset_directory=None):
    """
    éªŒè¯ç›®å½•ä¸‹çš„å¤šä¸ªæƒé‡æ–‡ä»¶
    
    Args:
        weights_dir: åŒ…å«æƒé‡æ–‡ä»¶çš„ç›®å½•
        plans_file: plansæ–‡ä»¶è·¯å¾„
        fold: äº¤å‰éªŒè¯çš„fold
        output_folder: è¾“å‡ºæ–‡ä»¶å¤¹
        dataset_directory: æ•°æ®é›†ç›®å½•
    """
    
    print(f"ğŸ” Validating multiple weights in: {weights_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰çš„.pthæ–‡ä»¶
    weight_files = []
    for file in os.listdir(weights_dir):
        if file.endswith('.pth'):
            weight_files.append(join(weights_dir, file))
    
    if not weight_files:
        print("âŒ No weight files found!")
        return
    
    print(f"Found {len(weight_files)} weight files")
    
    results = {}
    for weight_file in weight_files:
        print(f"\n{'='*50}")
        print(f"Validating: {os.path.basename(weight_file)}")
        print(f"{'='*50}")
        
        result = validate_single_weights(
            weights_path=weight_file,
            plans_file=plans_file,
            fold=fold,
            output_folder=output_folder,
            dataset_directory=dataset_directory
        )
        
        results[weight_file] = result
    
    return results

def main():
    """ä¸»å‡½æ•° - é…ç½®å¹¶è¿è¡ŒéªŒè¯"""
    
    # ========== é…ç½®åŒºåŸŸ ==========
    # æƒé‡æ–‡ä»¶è·¯å¾„ï¼ˆå•ä¸ªæ–‡ä»¶æˆ–ç›®å½•ï¼‰
    WEIGHTS_PATH = "/data/dusy/nnUNet/nnUNet_trained_models/nnUNet/3d_fullres/Task004_Hippocampus/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/averaged_model_final.pth"
    
    # Plansæ–‡ä»¶è·¯å¾„
    PLANS_FILE = "/data/dusy/nnUNet/nnUNet_trained_models/nnUNet/3d_fullres/Task004_Hippocampus/nnUNetTrainerV2__nnUNetPlansv2.1/plans.pkl"
    
    # æ•°æ®é›†ç›®å½•
    DATASET_DIRECTORY = "/data/dusy/nnUNet/nnUNet_preprocessed/Task004_Hippocampus"
    
    # Foldç¼–å·
    FOLD = 0
    
    # è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºæƒé‡æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼‰
    OUTPUT_FOLDER = None
    # =============================
    
    print("ğŸš€ Starting Weight Validation")
    print("=" * 50)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(WEIGHTS_PATH):
        print(f"âŒ Weights path does not exist: {WEIGHTS_PATH}")
        return
    
    if not os.path.exists(PLANS_FILE):
        print(f"âŒ Plans file does not exist: {PLANS_FILE}")
        return
    
    # åˆ¤æ–­æ˜¯å•ä¸ªæ–‡ä»¶è¿˜æ˜¯ç›®å½•
    if os.path.isfile(WEIGHTS_PATH):
        # éªŒè¯å•ä¸ªæƒé‡æ–‡ä»¶
        validate_single_weights(
            weights_path=WEIGHTS_PATH,
            plans_file=PLANS_FILE,
            fold=FOLD,
            output_folder=OUTPUT_FOLDER,
            dataset_directory=DATASET_DIRECTORY
        )
    else:
        # éªŒè¯ç›®å½•ä¸‹çš„æ‰€æœ‰æƒé‡æ–‡ä»¶
        validate_multiple_weights(
            weights_dir=WEIGHTS_PATH,
            plans_file=PLANS_FILE,
            fold=FOLD,
            output_folder=OUTPUT_FOLDER,
            dataset_directory=DATASET_DIRECTORY
        )
    
    print("\nğŸ‰ All validations completed!")

if __name__ == "__main__":
    main()