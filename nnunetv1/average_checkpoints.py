import os
import torch
import glob
import re
from collections import OrderedDict

def average_checkpoints_with_proper_saving(checkpoints_dir, output_path, num_best=30):
    """
    ä¿®å¤ç‰ˆæœ¬ï¼šç¡®ä¿ä¿å­˜è®¾ç½®ä¸åŸå§‹checkpointä¸€è‡´
    """
    
    print(f"Looking for checkpoints in: {checkpoints_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰checkpointæ–‡ä»¶
    checkpoint_files = glob.glob(os.path.join(checkpoints_dir, "checkpoint_epoch_*.pth"))
    
    if not checkpoint_files:
        print("No checkpoint files found!")
        return False
    
    print(f"Found {len(checkpoint_files)} checkpoint files")
    
    # æå–epochå’Œlossä¿¡æ¯
    checkpoint_info = []
    pattern = r'checkpoint_epoch_(\d+)\.pth'
    
    for checkpoint_file in checkpoint_files:
        match = re.search(pattern, os.path.basename(checkpoint_file))
        if match:
            epoch = int(match.group(1))
            try:
                checkpoint = torch.load(checkpoint_file, map_location='cpu', weights_only=False)
                if 'state_dict' not in checkpoint:
                    continue
                val_loss = checkpoint.get('val_loss', float('inf'))
                checkpoint_info.append((epoch, val_loss, checkpoint_file))
            except Exception as e:
                print(f"Error loading {checkpoint_file}: {e}")
    
    if not checkpoint_info:
        print("No valid checkpoints found!")
        return False
    
    # æŒ‰lossæ’åºï¼Œé€‰æ‹©æœ€ä½³çš„å‡ ä¸ª
    checkpoint_info.sort(key=lambda x: x[1])
    best_checkpoints = checkpoint_info[:num_best]
    
    print(f"\nSelected {len(best_checkpoints)} best checkpoints for averaging:")
    for i, (epoch, loss, path) in enumerate(best_checkpoints):
        print(f"  {i+1}. Epoch {epoch}: {loss:.4f}")
    
    # åˆ†æåŸå§‹checkpointçš„ä¿å­˜æ ¼å¼
    print("\nAnalyzing original checkpoint format...")
    first_checkpoint_path = best_checkpoints[0][2]
    first_checkpoint = torch.load(first_checkpoint_path, map_location='cpu', weights_only=False)
    
    # æ£€æŸ¥æ•°æ®ç±»å‹
    print("Checking data types in original checkpoint:")
    for key, tensor in list(first_checkpoint['state_dict'].items())[:5]:  # æ£€æŸ¥å‰5ä¸ª
        print(f"  {key}: {tensor.dtype}, size: {tuple(tensor.shape)}")
    
    # å¼€å§‹å¹³å‡æƒé‡
    print("\nAveraging weights...")
    
    averaged_state_dict = OrderedDict()
    num_loaded = 0
    
    # åˆå§‹åŒ–å¹³å‡å­—å…¸
    for key, tensor in first_checkpoint['state_dict'].items():
        # ä¿æŒåŸå§‹æ•°æ®ç±»å‹
        averaged_state_dict[key] = torch.zeros_like(tensor, dtype=tensor.dtype)
    
    for epoch, val_loss, checkpoint_path in best_checkpoints:
        try:
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            state_dict = checkpoint['state_dict']
            
            # ç´¯åŠ æƒé‡
            for key in averaged_state_dict:
                if key in state_dict:
                    # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
                    averaged_state_dict[key] += state_dict[key].to(averaged_state_dict[key].dtype)
            
            num_loaded += 1
            print(f"âœ“ Loaded epoch {epoch}")
            
        except Exception as e:
            print(f"âœ— Error processing epoch {epoch}: {e}")
    
    if num_loaded == 0:
        print("No checkpoints were successfully loaded!")
        return False
    
    # è®¡ç®—å¹³å‡å€¼
    print(f"\nCalculating average over {num_loaded} checkpoints...")
    for key in averaged_state_dict:
        averaged_state_dict[key] = averaged_state_dict[key] / num_loaded
    
    # ä¿å­˜å¹³å‡æ¨¡å‹ - ä½¿ç”¨ä¸åŸå§‹checkpointç›¸åŒçš„ç»“æ„
    print("\nSaving averaged model with proper format...")
    
    # åˆ›å»ºä¸€ä¸ªä¸åŸå§‹checkpointç»“æ„å®Œå…¨ç›¸åŒçš„å­—å…¸
    save_dict = {
        'state_dict': averaged_state_dict,
        'epochs_used': [epoch for epoch, _, _ in best_checkpoints],
        'val_losses': [loss for _, loss, _ in best_checkpoints],
        'num_checkpoints': num_loaded,
        'epoch': best_checkpoints[-1][0],  # æ·»åŠ epochä¿¡æ¯
        'optimizer': first_checkpoint.get('optimizer', None),  # ä¿æŒç›¸åŒçš„ç»“æ„
    }
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # æ–¹æ³•1: ä½¿ç”¨ä¸åŸå§‹ç›¸åŒçš„ä¿å­˜é€‰é¡¹
    print("Saving with torch.save (default options)...")
    torch.save(save_dict, output_path)
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    if os.path.exists(output_path):
        file_size = os.path.getsize(output_path) / (1024*1024)
        original_size = os.path.getsize(first_checkpoint_path) / (1024*1024)
        
        print(f"\nğŸ“Š File size comparison:")
        print(f"  Original: {original_size:.2f} MB")
        print(f"  Averaged: {file_size:.2f} MB")
        print(f"  Ratio: {file_size/original_size:.2f}")
        
        # å¦‚æœæ–‡ä»¶å¤§å°ä»ç„¶ä¸åŒ¹é…ï¼Œå°è¯•å…¶ä»–ä¿å­˜æ–¹æ³•
        if file_size < original_size * 0.8:  # å¦‚æœå°äº80%
            print("\nTrying alternative saving methods...")
            
            # æ–¹æ³•2: ä½¿ç”¨_use_new_zipfile_serialization=False (PyTorchæ—§æ ¼å¼)
            alt_path1 = output_path.replace('.pth', '_alt1.pth')
            torch.save(save_dict, alt_path1, _use_new_zipfile_serialization=False)
            alt1_size = os.path.getsize(alt_path1) / (1024*1024)
            print(f"  Alternative 1 (old format): {alt1_size:.2f} MB")
            
            # æ–¹æ³•3: ä½¿ç”¨pickleåè®®
            import pickle
            alt_path2 = output_path.replace('.pth', '_alt2.pth')
            with open(alt_path2, 'wb') as f:
                pickle.dump(save_dict, f, protocol=4)
            alt2_size = os.path.getsize(alt_path2) / (1024*1024)
            print(f"  Alternative 2 (pickle): {alt2_size:.2f} MB")
            
            # é€‰æ‹©æœ€æ¥è¿‘åŸå§‹å¤§å°çš„æ–‡ä»¶
            sizes = {
                'default': file_size,
                'old_format': alt1_size,
                'pickle': alt2_size
            }
            best_method = min(sizes.keys(), key=lambda x: abs(sizes[x] - original_size))
            
            print(f"\nğŸ¯ Best matching method: {best_method} ({sizes[best_method]:.2f} MB)")
            
            if best_method != 'default':
                # æ›¿æ¢ä¸ºæœ€ä½³ç‰ˆæœ¬
                best_path = output_path.replace('.pth', f'_{best_method}.pth')
                os.rename(best_path, output_path)
                print(f"Replaced with {best_method} version")
                
                # åˆ é™¤å…¶ä»–ä¸´æ—¶æ–‡ä»¶
                for method, path in [('alt1', alt_path1), ('alt2', alt_path2)]:
                    if method != best_method and os.path.exists(path):
                        os.remove(path)
    
    print(f"\nâœ… Averaged model saved: {output_path}")
    return True

def analyze_saved_model(model_path):
    """åˆ†æä¿å­˜çš„æ¨¡å‹æ–‡ä»¶"""
    print(f"\nğŸ” Analyzing saved model: {model_path}")
    
    if not os.path.exists(model_path):
        print("Model file not found!")
        return
    
    file_size = os.path.getsize(model_path) / (1024*1024)
    print(f"File size: {file_size:.2f} MB")
    
    # æ£€æŸ¥æ˜¯å¦å¯ä»¥åŠ è½½
    try:
        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        print("âœ… Model can be loaded successfully")
        
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
            print(f"State dict keys: {len(state_dict)}")
            
            # æ£€æŸ¥å‚æ•°æ•°é‡
            total_params = 0
            for key, tensor in state_dict.items():
                total_params += tensor.numel()
            print(f"Total parameters: {total_params:,}")
            
        if 'epochs_used' in checkpoint:
            print(f"Epochs used: {checkpoint['epochs_used']}")
            
    except Exception as e:
        print(f"âŒ Error loading model: {e}")

if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    checkpoints_dir = "/data/dusy/nnUNet/nnUNet_trained_models/nnUNet/3d_fullres/Task004_Hippocampus/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0"
    output_path = "/data/dusy/nnUNet/nnUNet_trained_models/nnUNet/3d_fullres/Task004_Hippocampus/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/averaged_model_final.pth"
    
    print("ğŸ§ª Starting checkpoint averaging with proper saving...")
    
    # è¿è¡Œå¹³å‡
    success = average_checkpoints_with_proper_saving(
        checkpoints_dir=checkpoints_dir,
        output_path=output_path,
        num_best=30
    )
    
    # åˆ†æç»“æœ
    if success:
        analyze_saved_model(output_path)
        print("\nğŸ‰ Process completed!")
        
        # æ¯”è¾ƒä¸åŸå§‹checkpoint
        checkpoint_files = glob.glob(os.path.join(checkpoints_dir, "checkpoint_epoch_*.pth"))
        if checkpoint_files:
            original_size = os.path.getsize(checkpoint_files[0]) / (1024*1024)
            averaged_size = os.path.getsize(output_path) / (1024*1024)
            print(f"\nğŸ“ˆ Final comparison:")
            print(f"  Original: {original_size:.2f} MB")
            print(f"  Averaged: {averaged_size:.2f} MB")
            print(f"  Ratio: {averaged_size/original_size:.2f}")
            
            # é‡è¦æç¤º
            if abs(averaged_size - original_size) / original_size < 0.1:
                print("âœ… File sizes are well matched!")
            else:
                print("âš ï¸  File sizes differ, but this might be normal due to:")
                print("   - Different PyTorch versions")
                print("   - Different compression settings")
                print("   - Metadata differences")
                print("   The important thing is that parameter counts match and the model loads correctly.")
    else:
        print("\nâŒ Averaging failed!")